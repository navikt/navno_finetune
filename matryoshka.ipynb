{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matryoshka embedding\n",
    "\n",
    "Matryoshka embedding er en metode for å trene en embeddingmodell til å\n",
    "\"strukturere\" embedding dimensjonene på en slik måte at vi kan fjerne\n",
    "dimensjoner uten å tape informasjon ^[Litt ytelse blir borte, men det skal ikke\n",
    "være katastrofalt som hvis man reduserer dimensjoner i en modell som ikke er\n",
    "trent på denne måten]. Dette gjør at vi kan redusere dimensjonaliteten til en\n",
    "embeddingmodell uten å tape for mye ytelse.\n",
    "\n",
    "Ved å redusere dimensjonaliteten til en embeddingmodell kan vi **redusere\n",
    "behovet for lagringsplass** i en vektordatabase. Dette kan være nyttig for å\n",
    "kunne utføre et semantisksøk hurtigere eller rett og slett spare penger på\n",
    "nødvendig lagringsplass.\n",
    "\n",
    "Mange embeddingmodeller støtter i dag Matryoshka embedding, noe som gjør at det\n",
    "er greit å kjenne til hvordan man kan finjustere en slik embeddingmodell.\n",
    "\n",
    "::: {.callout-important}\n",
    "Vi kommer til å gjenbruke data fra [Grunnleggende](./index.ipynb) og kommer ikke\n",
    "til å gjengi hvordan data er strukturert eller sammenstilt her.\n",
    "\n",
    "Hvis du ønsker å forstå hvordan vi har sammenstilt treningsdataene og hva som er\n",
    "innholdet, anbefaler vi at du gjør det først.\n",
    ":::\n",
    "\n",
    "::: {.callout-warning collapse=\"true\"}\n",
    "## Nødvendige avhengigheter\n",
    "\n",
    "Vi kommer til å bruke de samme pakkene som vi brukte i\n",
    "[Grunnleggende](./index.ipynb).\n",
    "\n",
    "Vi har følgende i `pyprojects.toml`:\n",
    "\n",
    "```toml\n",
    "dependencies = [\n",
    "    \"datasets>=3.3.2\",\n",
    "    \"polars[pyarrow]>=1.23.0\",\n",
    "    \"rich>=13.9.4\",\n",
    "    \"sentence-transformers[train]>=3.4.1\",\n",
    "    \"transformers[torch]>=4.49.0\",\n",
    "]\n",
    "```\n",
    "\n",
    "Samt `flash-attn` for CUDA-akselerasjon:\n",
    "\n",
    "```bash\n",
    "uv add flash-attn --no-build-isolation\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laste inn treningsdata\n",
    "\n",
    "Vi begynner med å laste inn treningsdata før vi gjør klar modellen og gjør\n",
    "endringene som trengs for Matryoshka embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "try:\n",
    "    from rich import print\n",
    "except ModuleNotFoundError:\n",
    "    pass\n",
    "\n",
    "# Les inn datasett\n",
    "test_dataset = pl.read_parquet(\"test_dataset.parquet\")\n",
    "train_dataset = pl.read_parquet(\"train_dataset.parquet\")\n",
    "# Kombiner for å kunne arbeide med hele datasettet\n",
    "dataset = pl.concat([test_dataset, train_dataset])\n",
    "# Skriv ut raske tall\n",
    "print(f\"Antall elementer [bold magenta]totalt[/]:\\t{len(dataset)}\")\n",
    "print(f\"Antall elementer i [bold green]trening[/]:\\t{len(train_dataset)}\")\n",
    "print(f\"Antall elementer i [bold blue]test[/]:\\t{len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi lager oss deretter et `corpus` og et sett med relevante dokumenter for mulige\n",
    "søk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merk at vi bruker `dataset` for å bruke _alt_ innhold\n",
    "corpus = dict(dataset.select([\"id\", \"positive\"]).rows())\n",
    "# For \"queries\" bruker vi det vi har plukket ut i test\n",
    "queries = dict(test_dataset.select([\"id\", \"anchor\"]).rows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = {}\n",
    "for qid in queries.keys():\n",
    "    # Hvert \"spørsmål\" vil være knyttet til en tittel fra Nav.no, vi henter ut\n",
    "    # denne tittelen og henter alle rader i datasettet med samme tittel som\n",
    "    # relevant dokument\n",
    "    q_pos = (\n",
    "        dataset.filter(pl.col(\"id\") == qid)\n",
    "        .unique(\"positive\")\n",
    "        .item(row=0, column=\"positive\")\n",
    "    )\n",
    "    relevant_docs[qid] = set([qid])\n",
    "    relevant_docs[qid].update(\n",
    "        set(dataset.filter(pl.col(\"positive\") == q_pos).get_column(\"id\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddingmodell og Matryoshka evaluering\n",
    "\n",
    "Det neste vi gjør er å definere embeddingmodell på samme måte som vi gjorde i\n",
    "[Grunnleggende](./index.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"Alibaba-NLP/gte-modernbert-base\",\n",
    "    # NOTE: Vi velger `device` tilpasset CUDA, for Mac kan man bruke `mps` og\n",
    "    # `cpu` vil alltid være tilgjengelig\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"mps\",\n",
    "    model_kwargs=dict(\n",
    "        attn_implementation=\"flash_attention_2\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"sdpa\",\n",
    "    ),\n",
    "    tokenizer_kwargs=dict(padding=\"max_length\", truncation=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Først nå vil koden endre seg fra tidligere. Når vi skal definere hvordan\n",
    "modellen skal evalueres så må vi få med reduksjon av dimensjonene som en del av\n",
    "evalueringen.\n",
    "\n",
    "Vi starter med å definere dimensjonene vi ønsker å benytte med modellen. Her er\n",
    "det **viktig at dimensjonene er strukturert fra størst til minst**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matryoshka_dimensions: list[int] = [768, 512, 256, 128, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "# Opprett liste med evalueringer per dimensjon\n",
    "sub_evaluators = []\n",
    "for dim in matryoshka_dimensions:\n",
    "    evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "        batch_size=64\n",
    "        if torch.cuda.is_available()\n",
    "        else 4,  # Skru denne ned eller opp avhengig av tilgjengelig minne, høyere gir raskere evaluering\n",
    "    )\n",
    "    sub_evaluators.append(evaluator)\n",
    "# Vi lager så en sekvensiel evaluator som kjører alle evalueringene etter\n",
    "# hverandre\n",
    "evaluator = SequentialEvaluator(sub_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "base_results = evaluator(model)\n",
    "\n",
    "for dim in matryoshka_dimensions:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print(f\"NDCG@10 for [bold magenta]{dim}[/] dimensjoner:\\t{base_results[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treningsmetode (loss function)\n",
    "\n",
    "For at vi skal kunne finjustere modellen må vi definere treningsmetode og\n",
    "oppsett spesielt tilpasset matryoshka embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MultipleNegativesRankingLoss, MatryoshkaLoss\n",
    "\n",
    "# Først definerer vi hvordan hver dimensjon skal rangeres\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model=model)\n",
    "# Før vi slår disse sammen med en \"meta\"-trener som trener én modell med flere\n",
    "# dimensjoner\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, loss=inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treningsoppsett\n",
    "\n",
    "Vi definerer deretter resten av treningsoppsettet som vi gjorde i\n",
    "[Grunnleggende](./index.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "\n",
    "# Definer hvordan trening skal foregå\n",
    "train_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"gte-modernbert-navno-matryoshka\",\n",
    "    num_train_epochs=4,  # Antall epoker å trene, flere er bedre\n",
    "    per_device_train_batch_size=128,  # Bestemt av maskinvare, høyere trener raskere\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_ratio=0.1,\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    tf32=True,  # Kjekt å sette til `True` hvis maskinvare støtter (krever nyere Nvidia GPU)\n",
    "    fp16=False,  # Sett til `True` hvis man ikke kan bruke `bf16`\n",
    "    bf16=True,  # Kjekt å sette på hvis maskinvare støtter (støttes av Mac og Nvidia GPU-er)\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # Veldig praktisk å fjerne duplikater når man har Positiv Pair\n",
    "    eval_on_start=True,\n",
    "    eval_strategy=\"epoch\",  # Evaluer etter hver X steg\n",
    "    save_strategy=\"epoch\",  # Lagre modell etter X steg\n",
    "    logging_steps=50,\n",
    "    save_total_limit=3,  # Bare spar på de 3 siste modellene\n",
    "    load_best_model_at_end=True,\n",
    "    # NOTE: Vi optimaliserer hele modellen for best mulig NDCG@10 med 128\n",
    "    # dimensjoner, dette er en endring fra hvordan vi gjorde det i\n",
    "    # \"Grunnlegende\"\n",
    "    metric_for_best_model=\"dim_128_cosine_ndcg@10\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi laster deretter inn treningsdataene i `datasets` før vi kan utføre selve\n",
    "treningen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_polars(train_dataset.select([\"anchor\", \"positive\"]))\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_ds,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utføre finjustering\n",
    "\n",
    "Tilslutt er det bare å utføre finjusteringen av modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "# Utfør trening\n",
    "trainer.train()\n",
    "\n",
    "# Pass på at vi lagrer modellen\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi evaluerer deretter en siste gang for å sammenligne hvordan ytelsen er for\n",
    "hver dimensjon sammenlignet med før finjustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "final_eval = evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "table = Table(title=\"Sammenligning av NDCG@10\")\n",
    "table.add_column(\"Før/etter finjustering\")\n",
    "for dim in matryoshka_dimensions:\n",
    "    table.add_column(f\"{dim}\")\n",
    "table.add_row(\n",
    "    \"Før\",\n",
    "    *[str(base_results[f\"dim_{dim}_cosine_ndcg@10\"]) for dim in matryoshka_dimensions],\n",
    ")\n",
    "table.add_row(\n",
    "    \"Etter\",\n",
    "    *[str(final_eval[f\"dim_{dim}_cosine_ndcg@10\"]) for dim in matryoshka_dimensions],\n",
    ")\n",
    "\n",
    "console = Console()\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Resultat av finjustering\n",
    "\n",
    "| Før/etter finjustering | 768 | 512 | 256 | 128 | 64 |\n",
    "|------------------------|-----|-----|-----|-----|----|\n",
    "| Før                    | 0.224 | 0.210 | 0.195 | 0.175 | 0.151 |\n",
    "| Etter                  | 0.377 | 0.369 | 0.368 | 0.356 | 0.305 |\n",
    "\n",
    "Som vi kan se fra tabellen over så gjør finjusteringen vår at selv så lite som\n",
    "`64` dimensjoner kan gi en god ytelse (bedre enn den originale modellen ved\n",
    "`768` dimensjoner)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
