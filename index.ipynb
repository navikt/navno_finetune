{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finjustere språkmodeller på Nav.no\n",
        "\n",
        "I denne notatboken skal vi illustrere hvordan man kan komme i gang med\n",
        "finjustering av språkmodeller. Vi skal gå gjennom stegene for å gjøre klart et\n",
        "datasett basert på data på [datamarkedsplassen](https://data.ansatt.nav.no/).\n",
        "Hvordan teste ytelsen på en embeddingmodell på dette datasettet. Og tilslutt,\n",
        "skal vi se hvordan vi kan forbedre ytelsen med finjustering.\n",
        "\n",
        "## Prosjektoppsett\n",
        "\n",
        "Vi anbefaler at man bruker [`uv`](https://docs.astral.sh/uv/) for å opprette\n",
        "prosjekt og styre avhengigheter.\n",
        "\n",
        "La oss starte med å lage et prosjekt:\n",
        "\n",
        "```bash\n",
        "uv init --app --python 3.12 navno_finetune\n",
        "```\n",
        "\n",
        "Inne i prosjektet kan vi fjerne `main.py` (eller `hello.py` avhengig av din\n",
        "versjon av `uv`). Hvis du ønsker å følge denne veiledningen kan man enkelt\n",
        "opprettet en Jupyter Notebook fil og klippe og lime kode fra veiledningen.\n",
        "Alternativt kan man strukturere kode etter eget ønske og bruke veiledningen til\n",
        "inspirasjon.\n",
        "\n",
        "::: {.callout collapse=\"true\"}\n",
        "## Gjenbruke _denne_ veiledningen\n",
        "\n",
        "Denne veiledningen er også mulig å gjenbruke ordrett. For å være enkelt å\n",
        "publisere er den strukturert som et Quarto prosjekt, men det er fullt mulig å\n",
        "klone veiledningen og bare kjøre Quarto filen direkte.\n",
        ":::\n",
        "\n",
        "## Datasett\n",
        "\n",
        "Før vi kan starte å finjustere trenger vi et datasett vi kan teste på og som vi\n",
        "kan bruke til trening. Vi kommer til å benytte [innholdet på\n",
        "Nav.no](https://data.ansatt.nav.no/dataproduct/6c7327e2-5894-4423-b6b2-52affa3f5b29/Innhold%20p%C3%A5%20Nav.no/7993897c-9fd4-46ee-86dd-5001621a2695)\n",
        "som utgangspunkt.\n",
        "\n",
        "### Laste ned rådata\n",
        "\n",
        "La oss starte med å laste ned rådata fra BigQuery. For å gjøre dette kommer vi\n",
        "til å bruke `google-cloud-bigquery` og [Polars](https://docs.pola.rs/).\n",
        "\n",
        "::: {.callout-note}\n",
        "## Nødvendige avhengigheter\n",
        "\n",
        "For å installere avhengigheter kjører vi følgende `uv` kommandoer:\n",
        "\n",
        "```bash\n",
        "uv add google-cloud-bigquery\n",
        "uv add polars --extra pyarrow\n",
        "```\n",
        ":::\n",
        "\n",
        "Vi starter med å hente all rådata og opprette en Polars `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jorgen/Projects/navno_finetune/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1820: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import polars as pl\n",
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client()\n",
        "\n",
        "# Bygg opp spørring og hent all data for gitt tidspunkt\n",
        "QUERY = (\n",
        "    'SELECT * FROM `nks-aiautomatisering-prod-194a.navno_crawl.navno` '\n",
        "    'WHERE DATE(crawl_date) = DATE(2025, 02, 25)')\n",
        "query_job = client.query(QUERY)\n",
        "rows = query_job.result()  # Vent på nedlasting\n",
        "\n",
        "df = pl.from_arrow(rows.to_arrow())  # Opprett dataframe med rådata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La oss inspisere dataene, før vi konverterer det til et mer passende format for\n",
        "språkmodeller."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>path</th><th>id</th><th>type</th><th>created</th><th>last_modified</th><th>crawl_date</th><th>language</th><th>anchor</th><th>taxonomy</th><th>area</th><th>owner</th><th>display_name</th><th>ingress</th><th>headers</th><th>content</th></tr><tr><td>str</td><td>str</td><td>str</td><td>datetime[μs, UTC]</td><td>datetime[μs, UTC]</td><td>datetime[μs, UTC]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>str</td><td>str</td><td>list[str]</td><td>str</td></tr></thead><tbody><tr><td>&quot;/afp-etteroppgjoret&quot;</td><td>&quot;3f7ccc77-148b-4c1b-9f03-ddcc27…</td><td>&quot;no.nav.navno:current-topic-pag…</td><td>2023-09-05 12:15:10.338 UTC</td><td>2023-09-05 12:41:40.281943 UTC</td><td>2025-02-25 12:40:51.156586 UTC</td><td>&quot;no&quot;</td><td>null</td><td>[]</td><td>[&quot;pension&quot;]</td><td>[&quot;familie_og_pensjonsytelser_styringsenhet&quot;]</td><td>&quot;Avtalefestet pensjon (AFP) og …</td><td>&quot;&quot;</td><td>[]</td><td>&quot;&lt;h4&gt;&lt;strong&gt;Har du fått brev o…</td></tr><tr><td>&quot;/protese-ortose-ortopediskesko…</td><td>&quot;3c26542b-cbac-4b7b-8266-4a7202…</td><td>&quot;no.nav.navno:situation-page&quot;</td><td>2022-06-20 11:49:32.143 UTC</td><td>2023-11-01 08:06:28.620071 UTC</td><td>2025-02-25 12:40:51.156586 UTC</td><td>&quot;no&quot;</td><td>&quot;reiseutgifter&quot;</td><td>[]</td><td>[&quot;accessibility&quot;]</td><td>[&quot;hjelpemidler_og_tilrettelegging&quot;]</td><td>&quot;Trenger en protese, ortose, or…</td><td>&quot;Om ortopediske hjelpemidler, o…</td><td>[&quot;&lt;h2&gt;Reiseutgifter&lt;/h2&gt;&quot;]</td><td>&quot;&lt;p&gt;Du kan få dekket reiseutgif…</td></tr><tr><td>&quot;/protese-ortose-ortopediskesko…</td><td>&quot;3c26542b-cbac-4b7b-8266-4a7202…</td><td>&quot;no.nav.navno:situation-page&quot;</td><td>2022-06-20 11:49:32.143 UTC</td><td>2023-11-01 08:06:28.620071 UTC</td><td>2025-02-25 12:40:51.156586 UTC</td><td>&quot;no&quot;</td><td>&quot;grunnstonad&quot;</td><td>[]</td><td>[&quot;accessibility&quot;]</td><td>[&quot;hjelpemidler_og_tilrettelegging&quot;]</td><td>&quot;Trenger en protese, ortose, or…</td><td>&quot;Om ortopediske hjelpemidler, o…</td><td>[&quot;&lt;h2&gt;Grunnstønad&lt;/h2&gt;&quot;]</td><td>&quot;&lt;p&gt;Du eller barnet ditt kan ha…</td></tr><tr><td>&quot;/protese-ortose-ortopediskesko…</td><td>&quot;3c26542b-cbac-4b7b-8266-4a7202…</td><td>&quot;no.nav.navno:situation-page&quot;</td><td>2022-06-20 11:49:32.143 UTC</td><td>2023-11-01 08:06:28.620071 UTC</td><td>2025-02-25 12:40:51.156586 UTC</td><td>&quot;no&quot;</td><td>&quot;aktuelle-produktsider&quot;</td><td>[]</td><td>[&quot;accessibility&quot;]</td><td>[&quot;hjelpemidler_og_tilrettelegging&quot;]</td><td>&quot;Trenger en protese, ortose, or…</td><td>&quot;Om ortopediske hjelpemidler, o…</td><td>[&quot;&lt;h2&gt;Aktuelle ordninger&lt;/h2&gt;&quot;]</td><td>&quot;&lt;div&gt;&lt;a href=&quot;/ortopediskesko&quot;…</td></tr><tr><td>&quot;/protese-ortose-ortopediskesko…</td><td>&quot;3c26542b-cbac-4b7b-8266-4a7202…</td><td>&quot;no.nav.navno:situation-page&quot;</td><td>2022-06-20 11:49:32.143 UTC</td><td>2023-11-01 08:06:28.620071 UTC</td><td>2025-02-25 12:40:51.156586 UTC</td><td>&quot;no&quot;</td><td>&quot;andre-som-kan-hjelpe&quot;</td><td>[]</td><td>[&quot;accessibility&quot;]</td><td>[&quot;hjelpemidler_og_tilrettelegging&quot;]</td><td>&quot;Trenger en protese, ortose, or…</td><td>&quot;Om ortopediske hjelpemidler, o…</td><td>[&quot;&lt;h2&gt;Andre som kan hjelpe&lt;/h2&gt;&quot;]</td><td>&quot;&lt;div&gt;&lt;a href=&quot;https://www.hjel…</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (5, 15)\n",
              "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
              "│ path      ┆ id        ┆ type      ┆ created   ┆ … ┆ display_n ┆ ingress   ┆ headers   ┆ content  │\n",
              "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ame       ┆ ---       ┆ ---       ┆ ---      │\n",
              "│ str       ┆ str       ┆ str       ┆ datetime[ ┆   ┆ ---       ┆ str       ┆ list[str] ┆ str      │\n",
              "│           ┆           ┆           ┆ μs, UTC]  ┆   ┆ str       ┆           ┆           ┆          │\n",
              "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
              "│ /afp-ette ┆ 3f7ccc77- ┆ no.nav.na ┆ 2023-09-0 ┆ … ┆ Avtalefes ┆           ┆ []        ┆ <h4><str │\n",
              "│ roppgjore ┆ 148b-4c1b ┆ vno:curre ┆ 5 12:15:1 ┆   ┆ tet       ┆           ┆           ┆ ong>Har  │\n",
              "│ t         ┆ -9f03-ddc ┆ nt-topic- ┆ 0.338 UTC ┆   ┆ pensjon   ┆           ┆           ┆ du fått  │\n",
              "│           ┆ c27…      ┆ pag…      ┆           ┆   ┆ (AFP) og  ┆           ┆           ┆ brev o…  │\n",
              "│           ┆           ┆           ┆           ┆   ┆ …         ┆           ┆           ┆          │\n",
              "│ /protese- ┆ 3c26542b- ┆ no.nav.na ┆ 2022-06-2 ┆ … ┆ Trenger   ┆ Om ortope ┆ [\"<h2>Rei ┆ <p>Du    │\n",
              "│ ortose-or ┆ cbac-4b7b ┆ vno:situa ┆ 0 11:49:3 ┆   ┆ en        ┆ diske hje ┆ seutgifte ┆ kan få   │\n",
              "│ topediske ┆ -8266-4a7 ┆ tion-page ┆ 2.143 UTC ┆   ┆ protese,  ┆ lpemidler ┆ r</h2>\"]  ┆ dekket   │\n",
              "│ sko…      ┆ 202…      ┆           ┆           ┆   ┆ ortose,   ┆ , o…      ┆           ┆ reiseutg │\n",
              "│           ┆           ┆           ┆           ┆   ┆ or…       ┆           ┆           ┆ if…      │\n",
              "│ /protese- ┆ 3c26542b- ┆ no.nav.na ┆ 2022-06-2 ┆ … ┆ Trenger   ┆ Om ortope ┆ [\"<h2>Gru ┆ <p>Du    │\n",
              "│ ortose-or ┆ cbac-4b7b ┆ vno:situa ┆ 0 11:49:3 ┆   ┆ en        ┆ diske hje ┆ nnstønad< ┆ eller    │\n",
              "│ topediske ┆ -8266-4a7 ┆ tion-page ┆ 2.143 UTC ┆   ┆ protese,  ┆ lpemidler ┆ /h2>\"]    ┆ barnet   │\n",
              "│ sko…      ┆ 202…      ┆           ┆           ┆   ┆ ortose,   ┆ , o…      ┆           ┆ ditt kan │\n",
              "│           ┆           ┆           ┆           ┆   ┆ or…       ┆           ┆           ┆ ha…      │\n",
              "│ /protese- ┆ 3c26542b- ┆ no.nav.na ┆ 2022-06-2 ┆ … ┆ Trenger   ┆ Om ortope ┆ [\"<h2>Akt ┆ <div><a  │\n",
              "│ ortose-or ┆ cbac-4b7b ┆ vno:situa ┆ 0 11:49:3 ┆   ┆ en        ┆ diske hje ┆ uelle ord ┆ href=\"/o │\n",
              "│ topediske ┆ -8266-4a7 ┆ tion-page ┆ 2.143 UTC ┆   ┆ protese,  ┆ lpemidler ┆ ninger</h ┆ rtopedis │\n",
              "│ sko…      ┆ 202…      ┆           ┆           ┆   ┆ ortose,   ┆ , o…      ┆ 2>\"…      ┆ kesko\"…  │\n",
              "│           ┆           ┆           ┆           ┆   ┆ or…       ┆           ┆           ┆          │\n",
              "│ /protese- ┆ 3c26542b- ┆ no.nav.na ┆ 2022-06-2 ┆ … ┆ Trenger   ┆ Om ortope ┆ [\"<h2>And ┆ <div><a  │\n",
              "│ ortose-or ┆ cbac-4b7b ┆ vno:situa ┆ 0 11:49:3 ┆   ┆ en        ┆ diske hje ┆ re som    ┆ href=\"ht │\n",
              "│ topediske ┆ -8266-4a7 ┆ tion-page ┆ 2.143 UTC ┆   ┆ protese,  ┆ lpemidler ┆ kan hjelp ┆ tps://ww │\n",
              "│ sko…      ┆ 202…      ┆           ┆           ┆   ┆ ortose,   ┆ , o…      ┆ e</h2…    ┆ w.hjel…  │\n",
              "│           ┆           ┆           ┆           ┆   ┆ or…       ┆           ┆           ┆          │\n",
              "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#| column: page\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strukturere data for språkmodeller\n",
        "\n",
        "For å finjustere en embeddingmodell er det i hovedsak _fire_ ulike måter å\n",
        "strukturere et datasett:\n",
        "\n",
        "- **Positive pair**: Et par setninger som er relatert (f.eks `(spørsmål,\n",
        "svar)`).\n",
        "- **Triplets**: Likt som _positive pair_, men med et anti-relatert element.\n",
        "    - Fordi vi kan bruke treningsfunksjoner (_loss_-funksjon) som kan gjennbruke\n",
        "    data i _positiv pair_ datasettet er ikke dette formatet like mye brukt.\n",
        "- **Pair with Similarity Score**: Et par setninger og en verdi som representerer\n",
        "hvor like disse setningene er.\n",
        "- **Text with Classes**: En setning med tilhørende klasse. Kan konverteres til\n",
        "andre formater over.\n",
        "\n",
        "::: {.column-margin}\n",
        "Hentet fra [SBERT.net - Dataset\n",
        "Overview](https://sbert.net/docs/sentence_transformer/dataset_overview.html).\n",
        ":::\n",
        "\n",
        "Basert på dataene over så er det naturlig å velge _Positiv Pair_. Dette er fordi\n",
        "vi kan koble flere kolonner sammen for å lage disse parene. Vi kan for eksempel\n",
        "koble tittel og innhold sammen, noe som burde forsterke koblingen mellom tittel\n",
        "og relevant innhold for språkmodellen.\n",
        "\n",
        "La oss starte med det åpenbare `(tittel, innhold)` paret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_title_content = df.select(\n",
        "    pl.col(\"display_name\").alias(\"anchor\"),\n",
        "    pl.col(\"content\").alias(\"positiv\")\n",
        ")\n",
        "df_title_content.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En annen åpenbar kobling er `(tittel, ingress)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_title_ingres = df.filter(\n",
        "    pl.col(\"ingress\").str.len_bytes() > 0).select(\n",
        "        pl.col(\"display_name\").alias(\"anchor\"),\n",
        "        pl.col(\"ingress\").alias(\"positiv\")\n",
        "    ).unique()\n",
        "df_title_ingres.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La oss også koble side tittel sammen med titler til innholdet og innhold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_all_titles_content = df.filter(pl.col(\"headers\").list.len() > 0).select(\n",
        "    (pl.col(\"display_name\") + \"\\n\" + pl.col(\"headers\").list.join(separator=\"\\n\")).alias(\"anchor\"),\n",
        "    pl.col(\"content\").alias(\"positiv\")\n",
        ")\n",
        "df_all_titles_content.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La oss koble alle disse tabellene sammen og for å lage et endelig datasett."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pl.concat([df_title_content, df_title_ingres, df_all_titles_content])\n",
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rense datasett\n",
        "\n",
        "Før vi sier oss fornøyd skal vi vaske dataene våre litt. I tabellene over har du\n",
        "kanskje lagt merke til at flere av kolonnene inneholder HTML elementer. Det er\n",
        "ikke i utgangspunktet noe galt å bruke dette for trening, men siden vi her\n",
        "fokuserer på en embeddingmodell ønsker vi at den fokuserer på semantikken og\n",
        "ikke formatet. Vi skal derfor prøve å renske bort alle HTML tag-er^[Vi gjør det\n",
        "enkelt med en `regex` inspirert av\n",
        "[StackOverflow](https://stackoverflow.com/a/12982689).]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = df_train.select(\n",
        "    pl.col(\"anchor\").str.replace_all(\"<.*?>\", \" \").str.strip_chars(),\n",
        "    pl.col(\"positiv\").str.replace_all(\"<.*?>\", \" \").str.strip_chars(),\n",
        ")\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lagre til fil\n",
        "\n",
        "La oss avslutte med å lagre data til en fil slik at vi enkelt kan gjenskape\n",
        "treningen og samtidig dele data med andre på en enkel måte. Et format som kan\n",
        "være praktisk er [Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) som\n",
        "både er effektivt for å lagre dataframe data og samtidig er godt støttet i de\n",
        "fleste verktøy vi bruker i Nav."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.write_parquet(\"dataset.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trening og test\n",
        "\n",
        "Nå som vi har laget et fullstendig treningssett kan vi begynne å tenke på å dele\n",
        "opp i en trenings del og en test del. Dette gjør vi for å ha en del som modellen\n",
        "får lov til å se på, trenings delen, og en del som er helt ny for modellen, test\n",
        "delen. Ved å skille slik får vi mulighet til å evaluere hvor godt modellen\n",
        "fungerer på ting den ikke har sett før.\n",
        "\n",
        "Vi starter med å legge til en `ID` kolonne på datasettet vårt slik at vi kan\n",
        "unikt identifisere rader, dette kommer vi til å trenge senere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pl.read_parquet(\"dataset.parquet\").with_row_index(\"id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deretter deler vi datasettet i en del for trening, meste parten, og en del for\n",
        "testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Litt komplisert å lage trening/test split i Polars\n",
        "#\n",
        "# Vi starter med å randomisere hele datasettet\n",
        "dataset = dataset.sample(fraction=1, shuffle=True, seed=12345)\n",
        "# Beregne antall rader vi skal bruke\n",
        "num_test = int(0.2 * len(dataset))\n",
        "# Deretter ta de første `num_test` radene til test\n",
        "test_dataset = dataset.head(num_test)\n",
        "# Tilslutt tar vi alle utenom de første `num_test` radene til trening\n",
        "train_dataset = dataset.tail(-num_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Corpus\n",
        "\n",
        "Nå som vi har opprettet et datasett kan vi bruke dette for å lage oss et corpus\n",
        "å trene på/med.\n",
        "\n",
        "Vi starter med å lage oss et sett med alt innhold, \"corpus\", og et sett med\n",
        "\"queries\" (de elementene som vi ønsker å teste mot innholdet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merk at vi bruker `dataset` for å bruke _alt_ innhold\n",
        "corpus = dict(dataset.select([\"id\", \"positiv\"]).rows())\n",
        "# For \"queries\" bruker vi det vi har plukket ut i test\n",
        "queries = dict(test_dataset.select([\"id\", \"anchor\"]).rows())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vi trenger så å lage oss en mapping mellom \"queries\" og relevant innhold. I vårt\n",
        "tilfellet så vil det være mer overlapp f.eks. fordi en tittel vil være relevant\n",
        "for flere innholdbiter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "relevant_docs = {}\n",
        "for qid, q in queries.items():\n",
        "    relevant_docs[qid] = dataset.filter(pl.col(\"anchor\") == q).get_column(\"id\").to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Språkmodell\n",
        "\n",
        "Nå som vi har ordnet oss med litt data er det endelig på tide å velge en\n",
        "språkmodell. Vi kommer til å bruke\n",
        "[`sentence-transformers`](https://sbert.net/index.html) for modellen og trening\n",
        "så la oss først ordne nødvendige pakker.\n",
        "\n",
        ":::: {.callout-note}\n",
        "## Nødvendige pakker\n",
        "\n",
        "Vi trenger et par pakker for `sentence-transformers` og de avhenger av riktig\n",
        "oppsett for effektiv trening.\n",
        "\n",
        "::: {.panel-tabset}\n",
        "## Uten CUDA (Linux, Mac og Windows uten GPU)\n",
        "For maskiner uten dedikert Nvidia GPU kan man enkelt installere som følger:\n",
        "\n",
        "```bash\n",
        "uv add transformers --extra torch\n",
        "uv add sentence-transformers --extra train\n",
        "```\n",
        "\n",
        "## CUDA\n",
        "\n",
        "Hvis du har et dedikert grafikkort kan du tjene mye på å installere PyTorch med\n",
        "CUDA støtte.\n",
        "\n",
        "Her anbefaler vi å følge oppskriften på [PyTorch sin\n",
        "hjemmeside](https://pytorch.org/get-started/locally/) for å få riktig oppsett\n",
        "for akkurat din maskin.\n",
        "\n",
        "Deretter trenger du:\n",
        "```bash\n",
        "uv add transformers\n",
        "uv add sentence-transformers --extra train\n",
        "```\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "Når det kommer til valg av språkmodell så er det vanskelig å gi noen konkrete\n",
        "anbefalinger, nettopp fordi man kan tilpasse modellene til egne data slik vi\n",
        "gjør her. En god oversikt over hvordan å velge språkmodell finnes i [Nav sin\n",
        "tekniske\n",
        "veileder](https://data.ansatt.nav.no/quarto/b9ec1385-d596-47e2-a3d2-8cbc85c577a3/_book/llm/lokale.html).\n",
        "\n",
        "Vi kommer til å gå videre med\n",
        "[`Alibaba-NLP/gte-modernbert-base`](https://huggingface.co/Alibaba-NLP/gte-modernbert-base).\n",
        "Denne har vi valgt av følgende grunner:\n",
        "\n",
        "- Den gjør det godt i sammenligninger mot embeddingmodeller av tilsvarende størrelse\n",
        "- Det er en relativt liten, $149$ millioner parametere, modell som burde passe\n",
        "fint på en laptop\n",
        "- Den har et stort kontekstvindu på $8192$ token\n",
        "- Den er lisensiert på en måte som gjør at vi enkelt kan ta den i bruk i Nav\n",
        "(`Apache 2.0`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\n",
        "    \"Alibaba-NLP/gte-modernbert-base\",\n",
        "    # Merk at her velger vi `device` spesifikt tilpasset Mac\n",
        "    # her burde man bruke \"cuda\" hvis tilgjengelig\n",
        "    device=\"mps\" if torch.backends.mps.is_available() else \"cpu\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluere språkmodell\n",
        "\n",
        "La oss nå se litt på hvordan modellen vår gjør det på datasettet vårt.\n",
        "\n",
        "Vi må starte med å definere en måte å evaluere modellen vår, her har også\n",
        "[`sentence-transformers` god\n",
        "støtte](https://sbert.net/docs/sentence_transformer/training_overview.html#evaluator)\n",
        "så vi benytter det som er innebygget der."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "from sentence_transformers.util import cos_sim\n",
        "\n",
        "evaluator = InformationRetrievalEvaluator(\n",
        "    queries=queries,\n",
        "    corpus=corpus,\n",
        "    relevant_docs=relevant_docs,\n",
        "    name=\"modernbert\",\n",
        "    score_functions={\"cosine\": cos_sim},\n",
        "    batch_size=4,\n",
        "    show_progress_bar=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deretter kan vi benytte `evaluator` til å vurdere modellene vår."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| eval: false\n",
        "base_eval = evaluator(model)\n",
        "print(base_eval)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
